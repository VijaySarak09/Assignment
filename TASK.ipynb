{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3741679d",
   "metadata": {},
   "source": [
    "#  Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8520697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import SGDRegressor, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b6680",
   "metadata": {},
   "source": [
    " 1) Read the target and type of regression to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_target_and_prediction_type(json_data):\n",
    "    target = json_data['design_state_data']['target']['target']\n",
    "    prediction_type = json_data['design_state_data']['target']['prediction_type']\n",
    "    return target, prediction_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93ead6",
   "metadata": {},
   "source": [
    "2)Read the features (which are column names in the csv) and figure out what missing imputation needs to be applied and apply that to the columns loaded in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46460473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features_and_impute(json_data, data):\n",
    "    feature_handling = json_data['design_state_data']['feature_handling']\n",
    "    for feature, details in feature_handling.items():\n",
    "        if details['is_selected']:\n",
    "            if details['feature_variable_type'] == 'numerical':\n",
    "                if details['feature_details']['missing_values'] == 'Impute':\n",
    "                    impute_value = details['feature_details']['impute_value']\n",
    "                    imputer = SimpleImputer(strategy='constant', fill_value=impute_value)\n",
    "                    data[feature] = imputer.fit_transform(data[[feature]])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3981b25",
   "metadata": {},
   "source": [
    "3) Compute feature reduction based on input. See the screenshot below where there can be No Reduction, Corr with Target, Tree-based, PCA. Please make sure you write code so that all options can work. If we rerun your code with a different Json it should work if we switch No Reduction to say PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4268c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_reduction(json_data, data):\n",
    "    reduction_method = json_data['design_state_data']['feature_reduction']['feature_reduction_method']\n",
    "    if reduction_method == 'Tree-based':\n",
    "        \n",
    "        num_of_features_to_keep = int(json_data['design_state_data']['feature_reduction']['num_of_features_to_keep'])\n",
    "        num_of_trees = int(json_data['design_state_data']['feature_reduction']['num_of_trees'])\n",
    "        depth_of_trees = int(json_data['design_state_data']['feature_reduction']['depth_of_trees'])\n",
    "        forest = ExtraTreesClassifier(n_estimators=num_of_trees, max_depth=depth_of_trees)\n",
    "        forest.fit(data.drop(columns=[target]), data[target])\n",
    "        importance = forest.feature_importances_\n",
    "        indices = importance.argsort()[-num_of_features_to_keep:][::-1]\n",
    "        selected_features = data.columns[indices]\n",
    "        data = data[selected_features.union([target])]\n",
    "    elif reduction_method == 'PCA':\n",
    "       \n",
    "        pca = PCA(n_components='mle')\n",
    "        data = pca.fit_transform(data.drop(columns=[target]))\n",
    "        data = pd.concat([pd.DataFrame(data), data[target]], axis=1)\n",
    "   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e22d6",
   "metadata": {},
   "source": [
    "4) Parse the Json and make the model objects (using sklean) that can handle what is required in the “prediction_type” specified in the JSON (See #1 where “prediction_type” is specified). Keep in mind not to pick models that don’t apply for the prediction_type specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_objects(prediction_type):\n",
    "    if prediction_type == 'Regression':\n",
    "        models = [\n",
    "            ('RandomForestRegressor', RandomForestRegressor()),\n",
    "            ('GradientBoostingRegressor', GradientBoostingRegressor()),\n",
    "            ('LinearRegression', LinearRegression()),\n",
    "            ('RidgeRegression', Ridge()),\n",
    "            ('LassoRegression', Lasso()),\n",
    "            ('ElasticNetRegression', ElasticNet()),\n",
    "            ('SGDRegressor', SGDRegressor()),\n",
    "            ('KNNRegressor', KNeighborsRegressor()),\n",
    "            ('ExtraTreesRegressor', ExtraTreesRegressor()),\n",
    "            ('NeuralNetworkRegressor', MLPRegressor())\n",
    "        ]\n",
    "    elif prediction_type == 'Classification':\n",
    "        models = [\n",
    "            ('RandomForestClassifier', RandomForestClassifier()),\n",
    "            ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "            ('LogisticRegression', LogisticRegression()),\n",
    "            ('SVM', SVC()),\n",
    "            ('SGDClassifier', SGDClassifier()),\n",
    "            ('KNNClassifier', KNeighborsClassifier()),\n",
    "            ('ExtraTreesClassifier', ExtraTreesClassifier()),\n",
    "            ('NeuralNetworkClassifier', MLPClassifier())\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid prediction_type specified in the JSON.\")\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f051a7f",
   "metadata": {},
   "source": [
    "5) Run the fit and predict on each model – keep in mind that you need to do hyper parameter tuning i.e., use GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_fit_and_predict(models, data, target):\n",
    "    for model_name, model in models:\n",
    "        params = json_data['design_state_data']['algorithms'][model_name]\n",
    "        if params['is_selected']:\n",
    "            pipeline = Pipeline([\n",
    "                \n",
    "                ('model', model)\n",
    "            ])\n",
    "\n",
    "            \n",
    "            grid_params = {}  \n",
    "\n",
    "            \n",
    "            grid_search = GridSearchCV(pipeline, grid_params, cv=5, scoring='neg_mean_squared_error')\n",
    "            grid_search.fit(data.drop(columns=[target]), data[target])\n",
    "\n",
    "            \n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(\"Best Parameters:\", grid_search.best_params_)\n",
    "            print(\"Best Score (Negative MSE):\", grid_search.best_score_)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee814de",
   "metadata": {},
   "source": [
    "6) Log to the console the standard model metrics that apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426833f",
   "metadata": {},
   "outputs": [],
   "source": [
    " mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"Model Metrics for {model.named_steps['model']} - MSE: {mse}, R^2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d64b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb9a47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0da46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050263e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e3c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
